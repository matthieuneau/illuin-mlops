cluster_name: local-cluster

provider:
    type: local
    head_ip: localhost
    worker_ips: []

auth:
    ssh_user: matthieuneau
  
# Running Ray in Docker images is optional (this docker section can be commented out).
# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled. Assumes Docker is installed.
docker:
    image: "rayproject/ray-ml:latest-cpu" # You can change this to latest-cpu if you don't need GPU support and want a faster startup
    # image: rayproject/ray:latest-gpu   # use this one if you don't need ML dependencies, it's faster to pull
    container_name: "ray_container"
    # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
    # if no cached version is present.
    pull_before_run: False    #TODO: Change to true when moving to the cloud
    run_options:   # Extra options to pass into "docker run"
        - --ulimit nofile=65536:65536

# The minimum number of workers nodes to launch in addition to the head
min_workers: 0

# The maximum number of workers nodes to launch in addition to the head node
max_workers: 0

# Commands to start ray on the head node
head_start_ray_commands:
    - ray stop || true
    - ray start --head --port=6379 --object-store-memory=3_000_000_000